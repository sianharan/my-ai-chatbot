import streamlit as st
import google.generativeai as genai
import pandas as pd
import os

# 1. íŽ˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="êµìœ¡ ì •ì±… ë¶„ì„ ì „ë¬¸ê°€", layout="wide")
st.title("ðŸ¤– êµìœ¡ ì •ì±… ë¶„ì„ ì „ë¬¸ê°€ ì±—ë´‡")
st.info("ì •ì±… ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")

# 2. API ì„¤ì • ë° v1beta ìš°íšŒ ê°•ì œ ë¡œì§
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
    
    # [ê°€ìž¥ í•µì‹¬] transport='rest'ë¥¼ í†µí•´ v1betaë¡œ ìžë™ ë¦¬ë‹¤ì´ë ‰íŠ¸ë˜ëŠ” ê²ƒì„ ë¬¼ë¦¬ì ìœ¼ë¡œ ì°¨ë‹¨í•©ë‹ˆë‹¤.
    # ë˜í•œ api_versionì„ ëª…ì‹œì ìœ¼ë¡œ ì œì–´í•  ìˆ˜ ìžˆëŠ” êµ¬ì¡°ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    genai.configure(api_key=api_key, transport='rest')
    
    try:
        # ëª¨ë¸ëª…ì—ì„œ 'models/'ë¥¼ ìƒëžµí•˜ê³  ì´ë¦„ë§Œ ì‚¬ìš©í•˜ì—¬ v1 ì—”ë“œí¬ì¸íŠ¸ì— ì ‘ì†í•©ë‹ˆë‹¤.
        model = genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        st.error(f"ëª¨ë¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
else:
    st.error("âš ï¸ Streamlit Secretsì— 'GEMINI_API_KEY'ë¥¼ ë“±ë¡í•´ ì£¼ì„¸ìš”!")
    st.stop()

# 3. ë°ì´í„° ë¡œë“œ (ìºì‹± ì ìš©)
@st.cache_data
def load_policy_data(file_name):
    if not os.path.exists(file_name):
        return None, f"'{file_name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GitHubì— ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
    
    try:
        # ì—‘ì…€ ì—”ì§„ì„ openpyxlë¡œ ëª…ì‹œí•˜ì—¬ ì•ˆì •ì„±ì„ ë†’ìž…ë‹ˆë‹¤.
        df = pd.read_excel(file_name, engine='openpyxl')
        text_content = ""
        for i, row in df.iterrows():
            title = str(row.get('ì œëª©', 'ì œëª© ì—†ìŒ'))
            content = str(row.get('ë‚´ìš©', 'ë‚´ìš© ì—†ìŒ'))
            text_content += f"[{i+1}ë²ˆ ì œì•ˆ] ì œëª©: {title} / ë‚´ìš©: {content}\n\n"
        return text_content, None
    except Exception as e:
        return None, f"ì—‘ì…€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# íŒŒì¼ëª… í™•ì¸
policy_text, error_msg = load_policy_data("ì •ì±…ì œì•ˆ_6ê°œì›”.xlsx")

if error_msg:
    st.error(error_msg)
    st.stop()

# 4. ì±„íŒ… ì‹œìŠ¤í…œ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ë‚´ì—­ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ì§ˆë¬¸ ì²˜ë¦¬ ë° AI ì‘ë‹µ
if prompt := st.chat_input("ì§ˆë¬¸ì„ ìž…ë ¥í•´ ì£¼ì„¸ìš”."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        with st.chat_message("assistant"):
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = f"""ë‹¹ì‹ ì€ êµìœ¡ ì •ì±… ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. 
ì•„ëž˜ [ë°ì´í„°]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. 
ë‹µë³€ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ë°ì´í„°ì˜ ë²ˆí˜¸(ì˜ˆ: [1ë²ˆ ì œì•ˆ])ë¥¼ ë°˜ë“œì‹œ ì–¸ê¸‰í•˜ì„¸ìš”.

[ë°ì´í„°]
{policy_text}

[ì§ˆë¬¸]
{prompt}"""
            
            # API í˜¸ì¶œ
            response = model.generate_content(full_prompt)
            
            if response and response.text:
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            else:
                st.error("ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ì˜ í• ë‹¹ëŸ‰ì„ í™•ì¸í•´ ë³´ì„¸ìš”.")
                
    except Exception as e:
        # ì´ ì‹œì ì—ì„œ ë°œìƒí•˜ëŠ” 404 ì˜¤ë¥˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ë¬¸ì œìž…ë‹ˆë‹¤.
        st.error(f"ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.info("íŒ: requirements.txtì˜ google-generativeai ë²„ì „ì„ >=0.8.3ìœ¼ë¡œ ìˆ˜ì • í›„ Reboot í•´ë³´ì„¸ìš”.")
