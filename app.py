import streamlit as st
import google.generativeai as genai
import pandas as pd

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI ì •ì±… ë¶„ì„ ì „ë¬¸ê°€", layout="wide")

st.title("ğŸ¤– êµìœ¡ ì •ì±… ë¶„ì„ ì „ë¬¸ê°€ ì±—ë´‡")
st.info("ì—‘ì…€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ê³µì§€ëŠ¥ì´ ì •ì±… ì œì•ˆì„ ë¶„ì„í•´ ë“œë¦½ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.header("ì„¤ì •")
user_api_key = st.sidebar.text_input("Gemini API Key ì…ë ¥", type="password")

# ì—‘ì…€ íŒŒì¼ ë¡œë“œ (ì‚¬ì „ì— GitHubì— ì˜¬ë¦° íŒŒì¼ëª…ê³¼ ì¼ì¹˜í•´ì•¼ í•¨)
file_path = "ì •ì±…ì œì•ˆ_6ê°œì›”.xlsx"

@st.cache_data
def load_data(path):
    try:
        df = pd.read_excel(path)
        all_text = ""
        for i, row in df.iterrows():
            title = str(row['ì œëª©'])
            content = str(row['ë‚´ìš©'])
            # ì•„ë˜ ì¤„ì´ ì˜¤ë¥˜ê°€ ë‚¬ë˜ ë¶€ë¶„ì…ë‹ˆë‹¤. ë”°ì˜´í‘œ ì§ì„ ì™„ë²½íˆ ë§ì·„ìŠµë‹ˆë‹¤.
            all_text += f"[{i+1}ë²ˆ ì œì•ˆ] ì œëª©: {title} / ë‚´ìš©: {content}\n\n"
        return all_text
    except Exception as e:
        return f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}"

all_policies = load_data(file_path)

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ì •ì±…ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
    if not user_api_key:
        st.error("ì‚¬ì´ë“œë°”ì— Gemini API Keyë¥¼ ë¨¼ì € ì…ë ¥í•´ ì£¼ì„¸ìš”!")
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            genai.configure(api_key=user_api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')
            
            # AIì—ê²Œ ì¤„ ëª…ë ¹ ìƒì„±
            full_prompt = f"ë„ˆëŠ” ì •ì±… ë¶„ì„ ì „ë¬¸ê°€ì•¼. ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì¤˜.\n\n[ë°ì´í„°]\n{all_policies}\n\n[ì§ˆë¬¸]\n{prompt}"
            
            with st.chat_message("assistant"):
                response = model.generate_content(full_prompt)
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
