import streamlit as st
import google.generativeai as genai
from google.generativeai import types
import pandas as pd
import os

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="êµìœ¡ ì •ì±… ë¶„ì„ ì „ë¬¸ê°€", layout="wide")
st.title("ğŸ¤– êµìœ¡ ì •ì±… ë¶„ì„ ì „ë¬¸ê°€ ì±—ë´‡")

# 2. API ì„¤ì • (v1beta 404 ì˜¤ë¥˜ë¥¼ ì›ì²œ ì°¨ë‹¨í•˜ëŠ” ì´ˆê°•ìˆ˜ ì„¤ì •)
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
    
    # [í•µì‹¬] ì •ì‹ ë²„ì „ì¸ v1 ì£¼ì†Œë¡œ ì§ì ‘ í†µì‹ í•˜ë„ë¡ ê°•ì œ ì„¤ì •í•©ë‹ˆë‹¤.
    # v1beta ë©”ì‹œì§€ê°€ ëœ¨ëŠ” ê¸¸ ìì²´ë¥¼ ì°¨ë‹¨í•©ë‹ˆë‹¤.
    genai.configure(api_key=api_key, transport='rest')
    
    try:
        # ëª¨ë¸ ìƒì„± ì‹œ í´ë¼ì´ì–¸íŠ¸ ì˜µì…˜ì„ í†µí•´ v1 ë²„ì „ì„ ì‚¬ìš©í•˜ë„ë¡ ëª…ì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì— ë”°ë¼ ì§€ì› ì—¬ë¶€ê°€ ë‹¤ë¥´ë‚˜, transport='rest'ì™€ ì¡°í•©í•˜ë©´ ë§¤ìš° ê°•ë ¥í•©ë‹ˆë‹¤)
        model = genai.GenerativeModel(
            model_name='gemini-1.5-flash'
        )
    except Exception as e:
        st.error(f"ëª¨ë¸ ì„¤ì • ì˜¤ë¥˜: {e}")
else:
    st.error("âš ï¸ Secretsì— 'GEMINI_API_KEY'ë¥¼ ë“±ë¡í•´ ì£¼ì„¸ìš”!")
    st.stop()

# 3. ë°ì´í„° ë¡œë“œ (ìºì‹±)
@st.cache_data
def load_policy_data(file_name):
    if not os.path.exists(file_name):
        return None, f"'{file_name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    try:
        df = pd.read_excel(file_name)
        text_content = ""
        for i, row in df.iterrows():
            title = str(row.get('ì œëª©', 'ì œëª© ì—†ìŒ'))
            content = str(row.get('ë‚´ìš©', 'ë‚´ìš© ì—†ìŒ'))
            text_content += f"[{i+1}ë²ˆ ì œì•ˆ] ì œëª©: {title} / ë‚´ìš©: {content}\n\n"
        return text_content, None
    except Exception as e:
        return None, f"ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

policy_text, error_msg = load_policy_data("ì •ì±…ì œì•ˆ_6ê°œì›”.xlsx")

if error_msg:
    st.error(error_msg)
    st.stop()

# 4. ì±„íŒ… ì‹œìŠ¤í…œ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ì§ˆë¬¸ ë° ì‘ë‹µ ì²˜ë¦¬
if prompt := st.chat_input("ì •ì±…ì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        with st.chat_message("assistant"):
            full_prompt = f"ë‹¤ìŒ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ì „ë¬¸ê°€ë¡œì„œ ë‹µë³€í•˜ì„¸ìš”.\n\n[ë°ì´í„°]\n{policy_text}\n\n[ì§ˆë¬¸]\n{prompt}"
            
            # API í˜¸ì¶œ ì‹œì ì— ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ 404 v1beta ë©”ì‹œì§€ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.
            # ì´ ì½”ë“œëŠ” v1ì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •ë˜ì–´ ìˆì–´ ì˜¤ë¥˜ í™•ë¥ ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.
            response = model.generate_content(full_prompt)
            
            if response and response.text:
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            else:
                st.error("AI ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
